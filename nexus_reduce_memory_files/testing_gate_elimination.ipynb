{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from antea  .io.mc_io    import load_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking size and configuration for every file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration for each file:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thr_charge</th>\n",
       "      <th>sns_only</th>\n",
       "      <th>tof_pe_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>false</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>true</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>true</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>true</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  thr_charge sns_only tof_pe_number\n",
       "1          2    false            10\n",
       "2          2     true            10\n",
       "3          2     true            20\n",
       "4          4     true            10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = ['thr_charge', 'sns_only', 'tof_pe_number']\n",
    "\n",
    "files = np.array([1, 2, 3, 4])\n",
    "\n",
    "conf_info = np.array([np.array([2, 'false', 10]), \n",
    "                      np.array([2,  'true', 10]), \n",
    "                      np.array([2,  'true', 20]), \n",
    "                      np.array([4,  'true', 10])])\n",
    "\n",
    "params_df = pd.DataFrame(data   =conf_info, \n",
    "                         index  =files, \n",
    "                         columns=params)\n",
    "print('Configuration for each file:')\n",
    "params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEXUS initial file:\n",
      "280.91 Mb (15000 events simulated, 7007 saved)\n",
      "\n",
      "NEXUS file2:\n",
      "213.15 Mb (15000 events simulated, 7007 saved)\n",
      "\n",
      "NEXUS file3\n",
      "84.17 Mb (15000 events simulated, 7007 saved)\n",
      "\n",
      "NEXUS file4\n",
      "97.28 Mb (15000 events simulated, 7007 saved)\n",
      "\n",
      "NEXUS file5:\n",
      "68.96 Mb (15000 events simulated, 7007 saved)\n",
      "\n",
      "File2 is 0.24% lighter\n",
      "File3 is 0.7% lighter\n",
      "File4 is 0.65% lighter\n",
      "File5 is 0.75% lighter\n"
     ]
    }
   ],
   "source": [
    "path  = '/data5/users/carmenromo/testing_nexus/data_ring/'\n",
    "file1 = path+'full_ring_iradius165mm_z140mm_depth3cm_pitch7mm_test1.100.pet.h5'\n",
    "file2 = path+'full_ring_iradius165mm_z140mm_depth3cm_pitch7mm_test3.000.pet.h5'\n",
    "file3 = path+'full_ring_iradius165mm_z140mm_depth3cm_pitch7mm_test4.000.pet.h5'\n",
    "file4 = path+'full_ring_iradius165mm_z140mm_depth3cm_pitch7mm_test5.000.pet.h5'\n",
    "file5 = path+'full_ring_iradius165mm_z140mm_depth3cm_pitch7mm_test6.000.pet.h5'\n",
    "\n",
    "total_size1 = os.path.getsize(file1)/1e6\n",
    "total_size2 = os.path.getsize(file2)/1e6\n",
    "total_size3 = os.path.getsize(file3)/1e6\n",
    "total_size4 = os.path.getsize(file4)/1e6\n",
    "total_size5 = os.path.getsize(file5)/1e6\n",
    "\n",
    "h5conf1     = load_configuration(file1)\n",
    "h5conf2     = load_configuration(file2)\n",
    "h5conf3     = load_configuration(file3)\n",
    "h5conf4     = load_configuration(file4)\n",
    "h5conf5     = load_configuration(file5)\n",
    "\n",
    "saved_evts1 = int(h5conf1[h5conf1.param_key=='saved_events'].param_value.values[0])\n",
    "saved_evts2 = int(h5conf2[h5conf2.param_key=='saved_events'].param_value.values[0])\n",
    "saved_evts3 = int(h5conf3[h5conf3.param_key=='saved_events'].param_value.values[0])\n",
    "saved_evts4 = int(h5conf4[h5conf4.param_key=='saved_events'].param_value.values[0])\n",
    "saved_evts5 = int(h5conf5[h5conf5.param_key=='saved_events'].param_value.values[0])\n",
    "\n",
    "print('NEXUS initial file:')\n",
    "print(f\"{round(total_size1, 2)} Mb (15000 events simulated, {saved_evts1} saved)\")\n",
    "print('')\n",
    "print('NEXUS file2:')\n",
    "print(f\"{round(total_size2, 2)} Mb (15000 events simulated, {saved_evts2} saved)\")\n",
    "print('')\n",
    "print('NEXUS file3')\n",
    "print(f\"{round(total_size3, 2)} Mb (15000 events simulated, {saved_evts3} saved)\")\n",
    "print('')\n",
    "print('NEXUS file4')\n",
    "print(f\"{round(total_size4, 2)} Mb (15000 events simulated, {saved_evts4} saved)\")\n",
    "print('')\n",
    "print('NEXUS file5:')\n",
    "print(f\"{round(total_size5, 2)} Mb (15000 events simulated, {saved_evts5} saved)\")\n",
    "print('')\n",
    "\n",
    "ratio1 = 1 - total_size2/total_size1\n",
    "ratio2 = 1 - total_size3/total_size1\n",
    "ratio3 = 1 - total_size4/total_size1\n",
    "ratio4 = 1 - total_size5/total_size1\n",
    "\n",
    "print(f\"File2 is {round(ratio1, 2)}% lighter\")\n",
    "print(f\"File3 is {round(ratio2, 2)}% lighter\")\n",
    "print(f\"File4 is {round(ratio3, 2)}% lighter\")\n",
    "print(f\"File5 is {round(ratio4, 2)}% lighter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that the tables are equal depending on the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from antea.io.mc_io import load_mcsns_response\n",
    "from antea.io.mc_io import load_mcTOFsns_response\n",
    "from antea.io.mc_io import load_mcparticles\n",
    "from antea.io.mc_io import load_mchits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No true info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.array([file2, file3, file4, file5])\n",
    "\n",
    "for i,(j,df_row) in zip(files, params_df.iterrows()):\n",
    "    sns_response     = load_mcsns_response   (i)\n",
    "    sns_tof_response = load_mcTOFsns_response(i)\n",
    "    particles        = load_mcparticles      (i)\n",
    "    hits             = load_mchits           (i)\n",
    "    \n",
    "    if df_row.sns_only == 'true':\n",
    "        assert particles.empty\n",
    "        assert hits     .empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charges above thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_response1 = load_mcsns_response(file1)\n",
    "sns_response3 = load_mcsns_response(file3)\n",
    "sns_response5 = load_mcsns_response(file5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df_above_thr3 = sns_response3[sns_response3.charge > 4].reset_index()\n",
    "df_above_thr3 = df_above_thr3.drop('index', axis=1)\n",
    "\n",
    "assert len(df_above_thr3) == len(sns_response5)\n",
    "print(df_above_thr3.equals(sns_response5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "df_above_thr1 = sns_response1[sns_response1.charge > 2].reset_index()\n",
    "df_above_thr1 = df_above_thr1.drop('index', axis=1)\n",
    "\n",
    "assert len(df_above_thr1) == len(sns_response2)\n",
    "assert len(df_above_thr1) == len(sns_response3)\n",
    "assert len(df_above_thr1) == len(sns_response4)\n",
    "print(df_above_thr1.equals(sns_response2))\n",
    "print(df_above_thr1.equals(sns_response3))\n",
    "print(df_above_thr1.equals(sns_response4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bin sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size0     = h5conf1[h5conf1.param_key==    'bin_size'].param_value.values[0]\n",
    "tof_bin_size0 = h5conf1[h5conf1.param_key=='tof_bin_size'].param_value.values[0]\n",
    "for i,(j,df_row) in zip(files, params_df.iterrows()):\n",
    "    h5config     = load_configuration(i)\n",
    "    bin_size     = h5config[h5config.param_key==    'bin_size'].param_value.values[0]\n",
    "    tof_bin_size = h5config[h5config.param_key=='tof_bin_size'].param_value.values[0]\n",
    "    assert bin_size     == bin_size0\n",
    "    assert tof_bin_size == tof_bin_size0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assert all the config parameters except the changed ones are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nexus/persistency/start_id\n",
      "['1500000' '0' '0' '0' '0']\n",
      "/nexus/persistency/hdf5\n",
      "['true' '2' '2' '2' '4']\n",
      "40 42\n"
     ]
    }
   ],
   "source": [
    "for i,j,k,l,m,n,o,p,q,r in zip(h5conf1.param_key, h5conf1.param_value, h5conf2.param_key, h5conf2.param_value,\n",
    "                               h5conf3.param_key, h5conf3.param_value, h5conf4.param_key, h5conf4.param_value,\n",
    "                               h5conf5.param_key, h5conf5.param_value):\n",
    "    if i=='/nexus/RegisterMacro' or i=='/nexus/persistency/outputFile':\n",
    "        continue\n",
    "    arr = np.array([j,l,n,p,r])\n",
    "    #print(i,k)\n",
    "    if not np.all(arr == arr[0]):\n",
    "        print(i)\n",
    "        print(arr)\n",
    "        \n",
    "print(len(h5conf1), len(h5conf2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_response_tof1 = load_mcTOFsns_response(file1)\n",
    "sns_response_tof2 = load_mcTOFsns_response(file2)\n",
    "\n",
    "particles2 = load_mcparticles(file2)\n",
    "events     = particles2.event_id.unique()\n",
    "for evt in range(1):\n",
    "    waveforms2     = sns_response2[sns_response2.event_id == evt]\n",
    "    sipms2         = waveforms2.sensor_id.values.astype(np.int32)\n",
    "    \n",
    "    tof_waveforms2 = sns_response_tof2[sns_response_tof2.event_id == evt].reset_index()\n",
    "    tof_waveforms2 = tof_waveforms2.drop('index', axis=1)\n",
    "    \n",
    "    tof_waveforms1 = sns_response_tof1[sns_response_tof1.event_id == evt+1500000]\n",
    "    sipms_tof1     = tof_waveforms1.sensor_id.values\n",
    "    for s_id in sipms2:\n",
    "        see  = tof_waveforms1[tof_waveforms1.sensor_id==-s_id].iloc[:10].drop('event_id', axis=1).reset_index().drop('index', axis=1)\n",
    "        see2 = tof_waveforms2[tof_waveforms2.sensor_id==-s_id]          .drop('event_id', axis=1).reset_index().drop('index', axis=1)\n",
    "        if not see.equals(see2):\n",
    "            print(see)\n",
    "            print(see2)\n",
    "            print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
