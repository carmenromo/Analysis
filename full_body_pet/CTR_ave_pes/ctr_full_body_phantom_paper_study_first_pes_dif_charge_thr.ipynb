{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import datetime\n",
    "import tables         as tb\n",
    "import numpy          as np\n",
    "import pandas         as pd\n",
    "\n",
    "import antea.database.load_db    as db\n",
    "import antea.reco.reco_functions as rf\n",
    "import antea.elec.tof_functions  as tf\n",
    "\n",
    "from antea.utils.map_functions import load_map\n",
    "from antea.io   .mc_io           import load_mchits\n",
    "from antea.io   .mc_io           import load_mcparticles\n",
    "from antea.io   .mc_io           import load_mcsns_response\n",
    "from antea.io   .mc_io           import load_mcTOFsns_response\n",
    "from antea.io   .mc_io           import read_sensor_bin_width_from_conf\n",
    "\n",
    "from invisible_cities.core import system_of_units as units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file /Users/carmenromoluque/Desktop/full_body_iradius380mm_z200cm_depth3cm_pitch7mm.000.pet.h5\n"
     ]
    }
   ],
   "source": [
    "### read sensor positions from database\n",
    "DataSiPM     = db.DataSiPMsim_only('petalo', 0)\n",
    "DataSiPM_idx = DataSiPM.set_index('SensorID')\n",
    "\n",
    "c0 = c1 = c2 = c3 = c4 = 0\n",
    "\n",
    "### TOF elec parameters:\n",
    "te_tdc         = 0.25\n",
    "n_sipms        = len(DataSiPM)\n",
    "first_sipm     = DataSiPM_idx.index.min()\n",
    "time_window    = 10000\n",
    "time_bin       = 5\n",
    "tau_sipm       = [100, 15000]\n",
    "time           = np.arange(0, 80000, time_bin)\n",
    "spe_resp, norm = tf.apply_spe_dist(time, tau_sipm)\n",
    "\n",
    "timestamp_thr   = [0, 0.5, 1.0, 1.5, 2.0, 2.5]\n",
    "num_of_init_pes = [1, 2, 3, 5, 8, 10, 12, 14, 16]\n",
    "\n",
    "ave_speed_in_LXe = 0.210       # mm/ps\n",
    "speed_in_vacuum  = 0.299792458 # mm/ps\n",
    "\n",
    "\n",
    "eventspath   = '/Users/carmenromoluque/Desktop/'\n",
    "filename     = eventspath + 'full_body_iradius380mm_z200cm_depth3cm_pitch7mm.000.pet.h5'\n",
    "print(f'Analyzing file {filename}')\n",
    "\n",
    "tof_bin_size = read_sensor_bin_width_from_conf(filename, tof=True)\n",
    "\n",
    "sns_response = pd.read_hdf(filename, 'MC/waveforms')\n",
    "sns_response_tof = pd.read_hdf(filename, 'MC/tof_waveforms')\n",
    "particles    = load_mcparticles(filename)\n",
    "hits         = load_mchits(filename)\n",
    "\n",
    "events = particles.event_id.unique()\n",
    "\n",
    "sipms         = DataSiPM_idx.loc[sns_response.sensor_id]\n",
    "sns_ids       = sipms.index.values\n",
    "sns_positions = np.array([sipms.X.values, sipms.Y.values, sipms.Z.values]).transpose()\n",
    "\n",
    "#charge_range = (0, 5000)\n",
    "charge_range = (1050, 1300)\n",
    "\n",
    "thr_r = 4\n",
    "thr_phi = 4\n",
    "thr_z = 4\n",
    "thr_e = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpos_file = '/Users/carmenromoluque/Analysis/full_body_phantom_paper/r_table_full_body_phantom_paper_thr4pes.h5'\n",
    "Rpos = load_map(rpos_file,\n",
    "                group  = \"Radius\",\n",
    "                node   = f\"f{int(thr_r)}pes150bins\",\n",
    "                x_name = \"PhiRms\",\n",
    "                y_name = \"Rpos\",\n",
    "                u_name = \"RposUncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carmenromoluque/miniconda3/envs/IC-3.7-2020-06-16/lib/python3.7/site-packages/ipykernel_launcher.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "30\n",
      "39\n",
      "44\n",
      "58\n",
      "59\n",
      "72\n",
      "98\n",
      "117\n",
      "119\n",
      "134\n",
      "135\n",
      "162\n",
      "167\n",
      "170\n",
      "171\n",
      "175\n",
      "184\n",
      "189\n",
      "192\n",
      "195\n",
      "211\n",
      "212\n",
      "226\n",
      "228\n",
      "244\n",
      "252\n",
      "253\n",
      "258\n",
      "268\n",
      "273\n",
      "279\n",
      "280\n",
      "314\n",
      "323\n",
      "326\n",
      "328\n",
      "334\n",
      "336\n",
      "338\n",
      "349\n",
      "369\n",
      "415\n",
      "423\n",
      "424\n",
      "432\n",
      "437\n",
      "448\n",
      "453\n",
      "469\n",
      "471\n",
      "472\n",
      "475\n",
      "484\n",
      "493\n",
      "495\n",
      "502\n",
      "513\n",
      "515\n",
      "518\n",
      "536\n",
      "538\n",
      "540\n",
      "550\n",
      "569\n",
      "583\n",
      "592\n",
      "603\n",
      "604\n",
      "608\n",
      "631\n",
      "641\n",
      "683\n",
      "697\n",
      "705\n",
      "713\n",
      "728\n",
      "740\n",
      "741\n",
      "746\n",
      "751\n",
      "754\n",
      "760\n",
      "765\n",
      "779\n",
      "790\n",
      "793\n",
      "806\n",
      "807\n",
      "813\n",
      "814\n",
      "819\n",
      "823\n",
      "834\n",
      "877\n",
      "879\n",
      "889\n",
      "899\n",
      "905\n",
      "928\n",
      "933\n",
      "945\n",
      "953\n",
      "972\n",
      "978\n",
      "999\n",
      "1000\n",
      "1002\n",
      "1007\n",
      "1011\n",
      "1023\n",
      "1027\n",
      "1042\n",
      "1048\n",
      "1050\n",
      "1062\n",
      "1066\n",
      "1084\n",
      "1088\n",
      "1101\n",
      "1130\n",
      "1137\n",
      "1138\n",
      "1156\n",
      "1168\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1227\n",
      "1228\n",
      "1240\n",
      "1243\n",
      "1250\n",
      "1254\n",
      "1295\n",
      "1315\n",
      "1319\n",
      "1326\n",
      "1329\n",
      "1346\n",
      "1352\n",
      "1365\n",
      "1377\n",
      "1379\n",
      "1388\n",
      "1389\n",
      "1413\n",
      "1438\n",
      "1451\n",
      "1456\n",
      "1472\n",
      "1480\n",
      "1483\n",
      "1487\n",
      "1501\n",
      "1507\n",
      "1511\n",
      "1514\n",
      "1540\n",
      "1574\n",
      "1599\n",
      "1608\n",
      "1619\n",
      "1623\n",
      "1632\n",
      "1634\n",
      "1644\n",
      "1645\n",
      "1655\n",
      "1660\n",
      "1674\n",
      "1677\n",
      "1681\n",
      "1683\n",
      "1700\n",
      "1702\n",
      "1705\n",
      "1719\n",
      "1723\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1763\n",
      "1778\n",
      "1786\n",
      "1806\n",
      "1823\n",
      "1825\n",
      "1832\n",
      "1845\n",
      "1864\n",
      "1873\n",
      "1878\n",
      "1887\n",
      "1898\n",
      "1905\n",
      "1911\n",
      "1935\n",
      "1942\n",
      "1969\n",
      "1975\n",
      "2004\n",
      "2009\n",
      "2011\n",
      "2021\n",
      "2022\n",
      "2030\n",
      "2039\n",
      "2044\n",
      "2048\n",
      "2061\n",
      "2069\n",
      "2077\n",
      "2082\n",
      "2107\n",
      "2119\n",
      "2123\n",
      "2131\n",
      "2149\n",
      "2162\n",
      "2180\n",
      "2200\n",
      "2214\n",
      "2215\n",
      "2237\n",
      "2262\n",
      "2269\n",
      "2271\n",
      "2277\n",
      "2294\n",
      "2305\n",
      "2308\n",
      "2318\n",
      "2333\n",
      "2341\n",
      "2354\n",
      "2368\n",
      "2369\n",
      "2377\n",
      "2378\n",
      "2389\n",
      "2396\n",
      "2445\n",
      "2464\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "for evt in events[:]:\n",
    "    evt_sns = sns_response[sns_response.event_id == evt]\n",
    "    evt_sns = rf.find_SiPMs_over_threshold(evt_sns, threshold=2)\n",
    "    if len(evt_sns) == 0:\n",
    "        continue\n",
    "\n",
    "    evt_parts = particles       [particles       .event_id == evt]\n",
    "    evt_hits  = hits            [hits            .event_id == evt]\n",
    "    evt_tof   = sns_response_tof[sns_response_tof.event_id == evt]\n",
    "\n",
    "    pos1, pos2, q1, q2, true_pos1, true_pos2, true_t1, true_t2, sns1, sns2 = rf.reconstruct_coincidences(evt_sns, charge_range, DataSiPM_idx, evt_parts, evt_hits)\n",
    "\n",
    "    if len(pos1) == 0 or len(pos2) == 0:\n",
    "        c0 += 1\n",
    "        continue\n",
    "\n",
    "    q1   = np.array(q1)\n",
    "    q2   = np.array(q2)\n",
    "    pos1 = np.array(pos1)\n",
    "    pos2 = np.array(pos2)\n",
    "\n",
    "    ## Calculate R\n",
    "    r1 = r2 = None\n",
    "\n",
    "    sel1_r = q1>thr_r\n",
    "    q1r    = q1  [sel1_r]\n",
    "    pos1r  = pos1[sel1_r]\n",
    "    sel2_r = q2>thr_r\n",
    "    q2r    = q2  [sel2_r]\n",
    "    pos2r  = pos2[sel2_r]\n",
    "\n",
    "    if len(pos1r) == 0 or len(pos2r) == 0:\n",
    "        c1 += 1\n",
    "        continue\n",
    "\n",
    "    pos1_phi  = rf.from_cartesian_to_cyl(np.array(pos1r))[:,1]\n",
    "    diff_sign = min(pos1_phi) < 0 < max(pos1_phi)\n",
    "    if diff_sign & (np.abs(np.min(pos1_phi))>np.pi/2.):\n",
    "        pos1_phi[pos1_phi<0] = np.pi + np.pi + pos1_phi[pos1_phi<0]\n",
    "    mean_phi = np.average(pos1_phi, weights=q1r)\n",
    "    var_phi1 = np.average((pos1_phi-mean_phi)**2, weights=q1r)\n",
    "    r1  = Rpos(np.sqrt(var_phi1)).value\n",
    "\n",
    "    pos2_phi  = rf.from_cartesian_to_cyl(np.array(pos2r))[:,1]\n",
    "    diff_sign = min(pos2_phi ) < 0 < max(pos2_phi)\n",
    "    if diff_sign & (np.abs(np.min(pos2_phi))>np.pi/2.):\n",
    "        pos2_phi[pos2_phi<0] = np.pi + np.pi + pos2_phi[pos2_phi<0]\n",
    "    mean_phi = np.average(pos2_phi, weights=q2r)\n",
    "    var_phi2 = np.average((pos2_phi-mean_phi)**2, weights=q2r)\n",
    "    r2  = Rpos(np.sqrt(var_phi2)).value\n",
    "    if np.isnan(r1) or np.isnan(r2):\n",
    "        continue\n",
    "\n",
    "    sel1_phi = q1>thr_phi\n",
    "    q1phi    = q1  [sel1_phi]\n",
    "    pos1phi  = pos1[sel1_phi]\n",
    "    sel2_phi = q2>thr_phi\n",
    "    q2phi    = q2  [sel2_phi]\n",
    "    pos2phi  = pos2[sel2_phi]\n",
    "    if len(q1phi) == 0 or len(q2phi) == 0:\n",
    "        c2 += 1\n",
    "        continue\n",
    "\n",
    "    phi1 = phi2 = None\n",
    "    reco_cart_pos = np.average(pos1phi, weights=q1phi, axis=0)\n",
    "    phi1 = np.arctan2(reco_cart_pos[1], reco_cart_pos[0])\n",
    "    reco_cart_pos = np.average(pos2phi, weights=q2phi, axis=0)\n",
    "    phi2 = np.arctan2(reco_cart_pos[1], reco_cart_pos[0])\n",
    "\n",
    "\n",
    "    sel1_z = q1>thr_z\n",
    "    q1z    = q1  [sel1_z]\n",
    "    pos1z  = pos1[sel1_z]\n",
    "    sel2_z = q2>thr_z\n",
    "    q2z    = q2  [sel2_z]\n",
    "    pos2z  = pos2[sel2_z]\n",
    "    if len(q1z) == 0 or len(q2z) == 0:\n",
    "        c3 += 1\n",
    "        continue\n",
    "\n",
    "    z1 = z2 = None\n",
    "    reco_cart_pos = np.average(pos1z, weights=q1z, axis=0)\n",
    "    z1 = reco_cart_pos[2]\n",
    "    reco_cart_pos = np.average(pos2z, weights=q2z, axis=0)\n",
    "    z2 = reco_cart_pos[2]\n",
    "\n",
    "    sel1_e = q1>thr_e\n",
    "    q1e    = q1[sel1_e]\n",
    "    sel2_e = q2>thr_e\n",
    "    q2e    = q2[sel2_e]\n",
    "    if len(q1e) == 0 or len(q2e) == 0:\n",
    "        c4 += 1\n",
    "        continue\n",
    "\n",
    "    pos1_cart = []\n",
    "    pos2_cart = []\n",
    "    if r1 and phi1 and z1 and len(q1) and r2 and phi2 and z2 and len(q2):\n",
    "        pos1_cart.append(r1 * np.cos(phi1))\n",
    "        pos1_cart.append(r1 * np.sin(phi1))\n",
    "        pos1_cart.append(z1)\n",
    "        pos2_cart.append(r2 * np.cos(phi2))\n",
    "        pos2_cart.append(r2 * np.sin(phi2))\n",
    "        pos2_cart.append(z2)\n",
    "    else: continue\n",
    "\n",
    "    a_cart1 = np.array(pos1_cart)\n",
    "    a_cart2 = np.array(pos2_cart)\n",
    "\n",
    "    ### Distance between interaction point and center of the geometry\n",
    "    geo_center = np.array([0,0,0])\n",
    "    dg1 = np.linalg.norm(a_cart1 - geo_center)\n",
    "    dg2 = np.linalg.norm(a_cart2 - geo_center)\n",
    "\n",
    "    times = evt_tof.time_bin.values * tof_bin_size / units.ps\n",
    "    evt_tof['time'] = np.round(np.random.normal(times, 0)).astype(int)\n",
    "\n",
    "    ## Tof convolution\n",
    "    tof_sns = evt_tof.sensor_id.unique()\n",
    "    evt_tof_exp_dist = []\n",
    "    for s_id in tof_sns:\n",
    "        tdc_conv    = tf.tdc_convolution(evt_tof, spe_resp, s_id, time_window)\n",
    "        tdc_conv_df = tf.translate_charge_conv_to_wf_df(evt, s_id, tdc_conv)\n",
    "        evt_tof_exp_dist.append(tdc_conv_df)\n",
    "    evt_tof_exp_dist = pd.concat(evt_tof_exp_dist)\n",
    "    \n",
    "    print(evt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_selected_times_of_sensors(evt_sns, evt_tof, sns_ids, num_sel_sns, DataSiPM_idx):\n",
    "    tof              = evt_tof[evt_tof.sensor_id.isin(sns_ids)]\n",
    "    min_ts           = tof.groupby(['sensor_id'])[['time']].min().sort_values('time')\n",
    "    mean_t_sel_sns   = min_ts[:num_sel_sns].time.mean()\n",
    "    ids_sel_sns      = min_ts[:num_sel_sns].index.values\n",
    "    evt_sns_sel_sns  = evt_sns[evt_sns.sensor_id.isin(-ids_sel_sns)]\n",
    "    charges_sel_sns  = evt_sns_sel_sns.groupby(['sensor_id'])[['charge']].sum().values.T[0]\n",
    "    sipms            = DataSiPM_idx.loc[evt_sns_sel_sns.sensor_id]\n",
    "    sns_positions    = np.array([sipms.X.values, sipms.Y.values, sipms.Z.values]).T\n",
    "    weig_pos_sel_sns = np.average(                sns_positions, axis=0, weights=charges_sel_sns)\n",
    "    weig_t_sel_sns   = np.average(min_ts[:num_sel_sns].time, axis=0, weights=charges_sel_sns)\n",
    "    return ids_sel_sns, charges_sel_sns, mean_t_sel_sns, weig_t_sel_sns, weig_pos_sel_sns\n",
    "\n",
    "\n",
    "def reconstruct_coincidences2(sns_response, tof_response, charge_range, DataSiPM_idx, particles, hits, num_of_init_pes):\n",
    "    if 'SensorID' in DataSiPM_idx.columns:\n",
    "        DataSiPM_idx = DataSiPM_idx.set_index('SensorID')\n",
    "\n",
    "    max_sns = sns_response[sns_response.charge == sns_response.charge.max()]\n",
    "    ## If by chance two sensors have the maximum charge, choose one (arbitrarily)\n",
    "    if len(max_sns != 1):\n",
    "        max_sns = max_sns[max_sns.sensor_id == max_sns.sensor_id.min()]\n",
    "    max_sipm = DataSiPM_idx.loc[max_sns.sensor_id]\n",
    "    max_pos  = np.array([max_sipm.X.values, max_sipm.Y.values, max_sipm.Z.values]).transpose()[0]\n",
    "\n",
    "    sipms         = DataSiPM_idx.loc[sns_response.sensor_id]\n",
    "    sns_ids       = sipms.index.astype('int64').values\n",
    "    sns_positions = np.array([sipms.X.values, sipms.Y.values, sipms.Z.values]).transpose()\n",
    "    sns_charges   = sns_response.charge\n",
    "\n",
    "    sns1, sns2, pos1, pos2, q1, q2 = rf.divide_sipms_in_two_hemispheres(sns_ids, sns_positions, sns_charges, max_pos)\n",
    "\n",
    "    tot_q1 = sum(q1)\n",
    "    tot_q2 = sum(q2)\n",
    "\n",
    "    sel1 = (tot_q1 > charge_range[0]) & (tot_q1 < charge_range[1])\n",
    "    sel2 = (tot_q2 > charge_range[0]) & (tot_q2 < charge_range[1])\n",
    "    if not sel1 or not sel2:\n",
    "        return [], [], [], [], None, None, None, None, [], [], None, None, None, None, [], []\n",
    "\n",
    "    ### TOF\n",
    "    ids_tof_tot1 , ids_tof_tot2  = [], []\n",
    "    mean_tof_tot1, mean_tof_tot2 = [], []\n",
    "    weig_tof_tot1, weig_tof_tot2 = [], []\n",
    "    weig_pos_tot1, weig_pos_tot2 = [], []\n",
    "    for num in num_of_init_pes:\n",
    "        ids_sel_sns1, _, mean_tof1, weig_tof1, weig_pos1 = find_selected_times_of_sensors(sns_response, tof_response, -sns1, num, DataSiPM_idx)\n",
    "        ids_sel_sns2, _, mean_tof2, weig_tof2, weig_pos2 = find_selected_times_of_sensors(sns_response, tof_response, -sns2, num, DataSiPM_idx)\n",
    "        ids_tof_tot1 .append(ids_sel_sns1)\n",
    "        ids_tof_tot2 .append(ids_sel_sns2)\n",
    "        mean_tof_tot1.append(mean_tof1)\n",
    "        mean_tof_tot2.append(mean_tof2)\n",
    "        weig_tof_tot1.append(weig_tof1)\n",
    "        weig_tof_tot2.append(weig_tof2)\n",
    "        weig_pos_tot1.append(weig_pos1)\n",
    "        weig_pos_tot2.append(weig_pos2)\n",
    "\n",
    "    true_pos1, true_pos2, true_t1, true_t2, _, _ = rf.find_first_interactions_in_active(particles, hits)\n",
    "\n",
    "    if not len(true_pos1) or not len(true_pos2):\n",
    "        print(\"Cannot find two true gamma interactions for this event\")\n",
    "        return [], [], [], [], None, None, None, None, [], [], None, None, None, None, [], []\n",
    "\n",
    "    scalar_prod = true_pos1.dot(max_pos)\n",
    "    if scalar_prod > 0:\n",
    "        int_pos1 = pos1\n",
    "        int_pos2 = pos2\n",
    "        int_q1   = q1\n",
    "        int_q2   = q2\n",
    "        int_min1 = ids_tof_tot1\n",
    "        int_min2 = ids_tof_tot2\n",
    "        int_mean_tof1 = mean_tof_tot1\n",
    "        int_mean_tof2 = mean_tof_tot2\n",
    "        int_weig_tof1 = weig_tof_tot1\n",
    "        int_weig_tof2 = weig_tof_tot2\n",
    "        weig_pos1     = weig_pos_tot1\n",
    "        weig_pos2     = weig_pos_tot2\n",
    "    else:\n",
    "        int_pos1 = pos2\n",
    "        int_pos2 = pos1\n",
    "        int_q1   = q2\n",
    "        int_q2   = q1\n",
    "        int_min1 = ids_tof_tot2\n",
    "        int_min2 = ids_tof_tot1\n",
    "        int_mean_tof1 = mean_tof_tot2\n",
    "        int_mean_tof2 = mean_tof_tot1\n",
    "        int_weig_tof1 = weig_tof_tot2\n",
    "        int_weig_tof2 = weig_tof_tot1\n",
    "        weig_pos1     = weig_pos_tot2\n",
    "        weig_pos2     = weig_pos_tot1\n",
    "\n",
    "    return int_pos1, int_pos2, int_q1, int_q2, true_pos1, true_pos2, true_t1, true_t2, int_min1, int_min2, int_mean_tof1, int_mean_tof2, int_weig_tof1, int_weig_tof2, weig_pos1, weig_pos2\n",
    "\n",
    "rpos_file = '/Users/carmenromoluque/Analysis/full_body_phantom_paper/r_table_full_body_phantom_paper_thr4pes.h5'\n",
    "Rpos = load_map(rpos_file,\n",
    "                group  = \"Radius\",\n",
    "                node   = f\"f{int(thr_r)}pes150bins\",\n",
    "                x_name = \"PhiRms\",\n",
    "                y_name = \"Rpos\",\n",
    "                u_name = \"RposUncertainty\")\n",
    "\n",
    "### read sensor positions from database\n",
    "DataSiPM     = db.DataSiPMsim_only('petalo', 0)\n",
    "DataSiPM_idx = DataSiPM.set_index('SensorID')\n",
    "\n",
    "c0 = c1 = c2 = c3 = c4 = 0\n",
    "\n",
    "### TOF elec parameters:\n",
    "tau_sipm       = [100, 15000]\n",
    "time_window    = 5000 #ps\n",
    "time           = np.arange(0, time_window)\n",
    "#time_bin       = 5 # ps\n",
    "#time           = np.arange(0, 80000, time_bin)\n",
    "#time           = time + (time_bin/2)\n",
    "spe_resp, norm = tf.apply_spe_dist(time, tau_sipm)\n",
    "\n",
    "timestamp_thr   = [0, 0.25, 0.5, 1.0]\n",
    "num_of_init_pes = [1, 2, 3, 5, 8, 10, 12, 14, 16]\n",
    "\n",
    "time_diff1 = [[[] for k in range(len(timestamp_thr))] for j in range(len(num_of_init_pes))]\n",
    "time_diff2 = [[[] for k in range(len(timestamp_thr))] for j in range(len(num_of_init_pes))]\n",
    "ave_t1     = [[[] for k in range(len(timestamp_thr))] for j in range(len(num_of_init_pes))]\n",
    "ave_t2     = [[[] for k in range(len(timestamp_thr))] for j in range(len(num_of_init_pes))]\n",
    "wei_t1     = [[[] for k in range(len(timestamp_thr))] for j in range(len(num_of_init_pes))]\n",
    "wei_t2     = [[[] for k in range(len(timestamp_thr))] for j in range(len(num_of_init_pes))]\n",
    "wpos1      = [[[] for k in range(len(timestamp_thr))] for j in range(len(num_of_init_pes))]\n",
    "wpos2      = [[[] for k in range(len(timestamp_thr))] for j in range(len(num_of_init_pes))]\n",
    "pos_cart1  = []\n",
    "pos_cart2  = []\n",
    "event_ids  = []\n",
    "\n",
    "ave_speed_in_LXe = 0.210       # mm/ps\n",
    "speed_in_vacuum  = 0.299792458 # mm/ps\n",
    "\n",
    "\n",
    "for number in range(start, start+numb):\n",
    "    number_str = \"{:03d}\".format(number)\n",
    "    filename  = f\"{eventsPath}/{file_name}.{number_str}.pet.h5\"\n",
    "    try:\n",
    "        #sns_response = load_mcsns_response(filename)\n",
    "        sns_response = pd.read_hdf(filename, 'MC/waveforms')\n",
    "    except ValueError:\n",
    "        print(f'File {filename} not found')\n",
    "        continue\n",
    "    except OSError:\n",
    "        print(f'File {filename} not found')\n",
    "        continue\n",
    "    except KeyError:\n",
    "        print(f'No object named MC/waveforms in file {filename}')\n",
    "        continue\n",
    "    print(f'Analyzing file {filename}')\n",
    "\n",
    "    tof_bin_size = read_sensor_bin_width_from_conf(filename, tof=True)\n",
    "\n",
    "    #sns_response_tof = load_mcTOFsns_response(filename)\n",
    "    sns_response_tof = pd.read_hdf(filename, 'MC/tof_waveforms')\n",
    "    particles        = load_mcparticles(filename)\n",
    "    hits             = load_mchits(filename)\n",
    "\n",
    "    events = particles.event_id.unique()\n",
    "\n",
    "    sipms         = DataSiPM_idx.loc[sns_response.sensor_id]\n",
    "    sns_ids       = sipms.index.values\n",
    "    sns_positions = np.array([sipms.X.values, sipms.Y.values, sipms.Z.values]).transpose()\n",
    "\n",
    "    #charge_range = (0, 5000)\n",
    "    charge_range = (1050, 1300)\n",
    "\n",
    "    \n",
    "\n",
    "        ## Trying different thresholds in charge for the sensor that sees the first pe:\n",
    "        for k, th in enumerate(timestamp_thr):\n",
    "            evt_tof_exp_dist = evt_tof_exp_dist[evt_tof_exp_dist.charge > th/norm]\n",
    "            _, _, _, _, _, _, _, _, min_ids1, min_ids2, mean_tof1, mean_tof2, weig_tof1, weig_tof2, weig_pos1, weig_pos2 = reconstruct_coincidences2(evt_sns, evt_tof_exp_dist, charge_range, DataSiPM_idx, evt_parts, evt_hits, num_of_init_pes)\n",
    "\n",
    "            for j, ipes in enumerate(num_of_init_pes):\n",
    "                if mean_tof1[j] == None or weig_tof1[j] == None:\n",
    "                    mean_t1 = mean_tof1[j]\n",
    "                    weig_t1 = weig_tof1[j]\n",
    "                else:\n",
    "                    mean_t1 = mean_tof1[j]/units.ps\n",
    "                    weig_t1 = weig_tof1[j]/units.ps\n",
    "\n",
    "                if mean_tof2[j] == None or weig_tof2[j] == None:\n",
    "                    mean_t2 = mean_tof2[j]\n",
    "                    weig_t2 = weig_tof2[j]\n",
    "                else:\n",
    "                    mean_t2  = mean_tof2[j]/units.ps\n",
    "                    weig_t2  = weig_tof2[j]/units.ps\n",
    "\n",
    "                ### Distance between interaction point and sensor detecting first photon\n",
    "                dp1 = np.linalg.norm(a_cart1 - weig_pos1[j])\n",
    "                dp2 = np.linalg.norm(a_cart2 - weig_pos2[j])\n",
    "\n",
    "                dg1 = np.linalg.norm(a_cart1)\n",
    "                dg2 = np.linalg.norm(a_cart2)\n",
    "\n",
    "                delta_t1 = mean_t2 - mean_t1 + (dp1 - dp2)/ave_speed_in_LXe + (dg1 - dg2)/speed_in_vacuum\n",
    "                delta_t2 = weig_t2 - weig_t1 + (dp1 - dp2)/ave_speed_in_LXe + (dg1 - dg2)/speed_in_vacuum\n",
    "\n",
    "                time_diff1[j][k].append(delta_t1)\n",
    "                time_diff2[j][k].append(delta_t2)\n",
    "                ave_t1    [j][k].append(mean_t1)\n",
    "                ave_t2    [j][k].append(mean_t2)\n",
    "                wei_t1    [j][k].append(weig_t1)\n",
    "                wei_t2    [j][k].append(weig_t2)\n",
    "                wpos1     [j][k].append(weig_pos1[j])\n",
    "                wpos2     [j][k].append(weig_pos2[j])\n",
    "\n",
    "        pos_cart1.append(a_cart1)\n",
    "        pos_cart2.append(a_cart2)\n",
    "        event_ids.append(evt)\n",
    "\n",
    "\n",
    "a_time_diff1 = np.array(time_diff1)\n",
    "a_time_diff2 = np.array(time_diff2)\n",
    "a_ave_t1     = np.array(ave_t1)\n",
    "a_ave_t2     = np.array(ave_t2)\n",
    "a_wei_t1     = np.array(wei_t1)\n",
    "a_wei_t2     = np.array(wei_t2)\n",
    "a_wpos1      = np.array(wpos1)\n",
    "a_wpos2      = np.array(wpos2)\n",
    "a_pos_cart1  = np.array(pos_cart1)\n",
    "a_pos_cart2  = np.array(pos_cart2)\n",
    "a_event_ids  = np.array(event_ids)\n",
    "\n",
    "np.savez(evt_file, time_diff1=a_time_diff1, time_diff2=a_time_diff2, ave_t1=a_ave_t1, ave_t2=a_ave_t2,\n",
    "         wei_t1=a_wei_t1, wei_t2=a_wei_t2, wpos1=a_wpos1, wpos2=a_wpos2, pos_cart1=a_pos_cart1,\n",
    "         pos_cart2=a_pos_cart2, event_ids=a_event_ids)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "\n",
    "print(f\"Not a coincidence: {c0}\")\n",
    "print(f\"Not passing threshold r = {c1}, phi = {c2}, z = {c3}, E = {c4}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
